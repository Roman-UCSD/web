{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d16289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import atm_adapter\n",
    "\n",
    "import tqdm\n",
    "import glob, os\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4654f",
   "metadata": {},
   "source": [
    "# Prepare models for publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6819",
   "metadata": {},
   "source": [
    "## HRFIT atmospheres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2dc65",
   "metadata": {},
   "source": [
    "Use the cell below to convert ATLAS and PHOENIX model atmospheres calculated with HRFIT into FITS files.\n",
    "\n",
    "**Note:** Choose between `adapt_phoenix()` and `adapt_atlas()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd5441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230717/56918304.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for model in tqdm.tqdm_notebook(models):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d132bd754dd4d309ffb80e7aba9f124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = '/media/roman/TeraTwo/website/ca2/'\n",
    "models = glob.glob('/media/roman/TeraTwo/christian/ca2/PHOENIX/*')\n",
    "\n",
    "for model in tqdm.tqdm_notebook(models):\n",
    "    try:\n",
    "        atm_adapter.adapt_phoenix(model, output_dir + model.split('/')[-1] + '.fits')\n",
    "    except:\n",
    "        print('Cannot pack {}'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3c3b3",
   "metadata": {},
   "source": [
    "## [LEGACY] ATMOS.UCSD.EDU atmospheres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f8808",
   "metadata": {},
   "source": [
    "Use the cell below to convert the models on atmos.ucsd.edu into FITS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, hashlib, gzip\n",
    "\n",
    "models = glob.glob('/media/roman/TeraTwo/website/atlas/*')\n",
    "output = '/media/roman/TeraTwo/website/output/'              # Save output here\n",
    "\n",
    "# MD5 hashes and identifiers of populations present in the input directory\n",
    "pops = {\n",
    "    '81f526240b1118a8371a27ccffdfb7d7': 'nominal',\n",
    "    'b71187e90bb2b2930ceab9350ef1879c': 'HMHA',\n",
    "    '6a1a292df6872327383cd557d6fdfda2': 'nominal',\n",
    "    '01f9fb93785d5630b841b6b901fd3a9b': 'HMMA',\n",
    "    'e4490f13948d6d242f623c977be5ce59': 'popIII',\n",
    "    '06ddffd8c02366baadffa02879a00282': 'HMET',\n",
    "    'dd5a0ce7edc86228c0208ff442e2ebd2': 'HMHA',\n",
    "    'b263e442553d6b3dbdf04733d7021e5b': 'HMMO',\n",
    "    'f54e05ce851c74e2d90439e25e8d54d4': 'LMHO',\n",
    "    '4fea898c6876647164e07637419a9d8b': 'HMMA',\n",
    "    'd3e776168b85c3919357d59f17b6910b': 'HMET',\n",
    "    '9641ed477799df2e9888962429321d2e': 'HMMO',\n",
    "    'e507badb75ffb9e60ee71eaa3139bb53': 'LMHO'\n",
    "}\n",
    "\n",
    "def meta_get_value(meta, field):\n",
    "    for category in meta:\n",
    "        for item in category['category_content']:\n",
    "            if item == field:\n",
    "                return category['category_content'][item]['value']\n",
    "    return False\n",
    "\n",
    "for model in tqdm.tqdm_notebook(models):\n",
    "    # Load and test model\n",
    "    try:\n",
    "        spectrum = np.loadtxt(model + '/spect.dat.gz', delimiter = ',', unpack = True)\n",
    "        f = gzip.open(model + '/spect.dat.gz', 'r')\n",
    "        spectrum_header = ''\n",
    "        while spectrum_header.find(',') == -1:\n",
    "            spectrum_header = f.readline().decode('utf-8').replace('#', '')\n",
    "        f.close()\n",
    "        spectrum_header = list(map(lambda s: s.strip(), spectrum_header.split(',')))\n",
    "        spectrum = dict(zip(spectrum_header, spectrum))\n",
    "        structure = np.loadtxt(model + '/struc.dat.gz', delimiter = ',', unpack = True)\n",
    "        f = gzip.open(model + '/struc.dat.gz', 'r')\n",
    "        structure_header = ''\n",
    "        while structure_header.find(',') == -1:\n",
    "            structure_header = f.readline().decode('utf-8').replace('#', '')\n",
    "        f.close()\n",
    "        structure_header = list(map(lambda s: s.strip(), structure_header.split(',')))\n",
    "        structure = dict(zip(structure_header, structure))\n",
    "        f = open(model + '/meta.json', 'r')\n",
    "        meta = json.loads(f.read())\n",
    "        f.close()\n",
    "    except:\n",
    "        print('{} is corrupted!'.format(model))\n",
    "        continue\n",
    "\n",
    "    # Extract abundances and hence determine the output directory\n",
    "    found = False\n",
    "    for i in range(len(meta)):\n",
    "        if meta[i]['category_title'] == 'Elemental composition':\n",
    "            if ('alpha' in meta[i]['category_content']) and (float(meta[i]['category_content']['alpha']['value']) != 0.0):\n",
    "                print('Non-zero alpha in {}'.format(model))\n",
    "            abundances = meta[i]['category_content']['zscale']['value'] + '|' + '|' + meta[i]['category_content']['eheu']['value']\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        print('Cannot find abundances for {}'.format(model))\n",
    "        continue\n",
    "    if (hash := hashlib.md5(abundances.encode('utf-8')).hexdigest()) not in pops:\n",
    "        raise ValueError('Found undefined population: {}'.format(hash))\n",
    "    output_dir = pops[hashlib.md5(abundances.encode('utf-8')).hexdigest()]\n",
    "    output_dir = output + output_dir + '/' + output_dir\n",
    "\n",
    "    # Build FITS headers\n",
    "    headers = {\n",
    "        'SOFTWARE': meta_get_value(meta, 'software'),\n",
    "        'TEFF': float(meta_get_value(meta, 'teff')),\n",
    "        'LOGG': float(meta_get_value(meta, 'logg')),\n",
    "        'ZSCALE': float(meta_get_value(meta, 'zscale')),\n",
    "        'RADIUS': float(meta_get_value(meta, 'r0')),\n",
    "        'X': float(meta_get_value(meta, 'X')),\n",
    "        'Y': float(meta_get_value(meta, 'Y')),\n",
    "        'Z': float(meta_get_value(meta, 'Z')),\n",
    "        'VTURB': float(meta_get_value(meta, ['synthe_vturb', 'xi'][meta_get_value(meta, 'software').lower().find('phoenix') != -1]).replace(' + convection', '')),\n",
    "        'MIXLEN': float(meta_get_value(meta, 'mixlen')),\n",
    "        'DUST': meta_get_value(meta, 'igrains') == 'Enabled',\n",
    "        'CLOUDS': meta_get_value(meta, 'use_clouds') == 'Enabled',\n",
    "        'CLDALPHA': float(meta_get_value(meta, 'cloud_covering_factor')),\n",
    "        'SETTL': meta_get_value(meta, 'settleos') == 'Enabled',\n",
    "        'GEOMETRY': ['PLANE-PARALLEL', 'SPHERICAL'][meta_get_value(meta, 'software').lower().find('phoenix') != -1],\n",
    "        'AIRORVAC': ([meta_get_value(meta, 'synthe_mode'), 'VAC'][meta_get_value(meta, 'software').lower().find('phoenix') != -1]).upper(),\n",
    "    }\n",
    "\n",
    "    # Software-specific corrections\n",
    "    if meta_get_value(meta, 'software').lower().find('phoenix') != -1:\n",
    "        spectrum['Intensity [erg s^-1 cm^-2 A^-1 sr^-1]'] = spectrum['Intensity [erg s^-1 cm^-2 A^-1 sr^-1]'] / np.pi ** 2.0 * 10\n",
    "        tau_label = 'Optical depth at {} AA'.format(meta_get_value(meta, 'wltau'))\n",
    "    else:\n",
    "        structure['Convective flux fraction (Fconv)'] = structure['Convective flux fraction (Fconv)'] / (atm_adapter.scp.sigma * 1e3 * headers['TEFF'] ** 4 / (4 * np.pi))\n",
    "        tau_label = 'Rosseland optical depth'\n",
    "\n",
    "\n",
    "    # Save to FITS\n",
    "    tables = []\n",
    "\n",
    "    columns = {\n",
    "        'wl': fits.Column(name = 'Wavelength', array = spectrum['Wavelength [A]'], format = 'D', unit = 'AA'),\n",
    "        'flux': fits.Column(name = 'Flux density', array = spectrum['Intensity [erg s^-1 cm^-2 A^-1 sr^-1]'] * np.pi, format = 'D', unit = 'ERG/S/CM2/AA'),\n",
    "    }\n",
    "    hdr = fits.Header()\n",
    "    hdr['TABLE'] = 'Emergent spectrum'\n",
    "    tables += [fits.BinTableHDU.from_columns(columns.values(), header = hdr)]\n",
    "\n",
    "    columns = {\n",
    "        'tau': fits.Column(name = tau_label, array = structure['Optical depth (tau)'], format = 'D', unit = 'NONE'),\n",
    "        'temp': fits.Column(name = 'Temperature', array = structure['Temperature [K]'], format = 'D', unit = 'K'),\n",
    "        'pgas': fits.Column(name = 'Gas pressure', array = structure['Gas pressure [bar]'] * 1e6, format = 'D', unit = 'DYN/CM2'),\n",
    "        'cmass': fits.Column(name = 'Column mass density', array = structure['Mass column density [g cm^-2]'], format = 'D', unit = 'G/CM2'),\n",
    "        'fconv': fits.Column(name = 'Convective flux fraction', array = structure['Convective flux fraction (Fconv)'], format = 'D', unit = 'NONE'),\n",
    "    }\n",
    "    hdr = fits.Header()\n",
    "    hdr['TABLE'] = 'Atmospheric structure'\n",
    "    tables += [fits.BinTableHDU.from_columns(columns.values(), header = hdr)]\n",
    "\n",
    "    eheu = meta_get_value(meta, 'eheu').split('|')\n",
    "    element_name = []\n",
    "    element_abundance = []\n",
    "    for i in range(3, 100):\n",
    "        if i not in atm_adapter.chemical_symbols:\n",
    "            continue\n",
    "        for element in eheu:\n",
    "            element = element.split(':')\n",
    "            if element[0] == atm_adapter.chemical_symbols[i]:\n",
    "                element_name += [element[0]]\n",
    "                element_abundance += [float(element[1])]\n",
    "    columns = {\n",
    "        'element': fits.Column(name = 'Element', array = element_name, format = 'A2'),\n",
    "        'eheu': fits.Column(name = 'Relative abundance', array = element_abundance, format = 'D', unit = 'DEX'),\n",
    "    }\n",
    "    hdr = fits.Header()\n",
    "    hdr['TABLE'] = 'Chemical composition'\n",
    "    tables += [fits.BinTableHDU.from_columns(columns.values(), header = hdr)]\n",
    "\n",
    "    hdr = fits.Header()\n",
    "    for key in headers:\n",
    "        hdr[key] = headers[key]\n",
    "\n",
    "    hdul = fits.HDUList([fits.PrimaryHDU(header=hdr)] + tables)\n",
    "    hdul.writeto(output_dir + '_{}_{}.fits'.format(int(headers['TEFF']), headers['LOGG']), overwrite = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b281b17",
   "metadata": {},
   "source": [
    "## HRFIT interiors\n",
    "\n",
    "Use the cell below to prepare MESA tables for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f03657b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/roman/TeraTwo/website/GAv0/ca2/MESA/custom.patch'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "# Export the individual MESA models\n",
    "def export_MESA_model(model, export_to):\n",
    "    files = ['history_columns.list', 'inlist', 'inlist_pgstar', 'inlist_project', 'LOGS/history.data', 'output.mod', 'output.out', 'src/*']\n",
    "    for file in files:\n",
    "        for file in glob.glob(model + '/' + file):\n",
    "            destination = export_to + '/' + os.path.relpath(file, model + '/..')\n",
    "            os.makedirs(os.path.dirname(destination), exist_ok = True)\n",
    "            shutil.copy(file, destination)\n",
    "\n",
    "# Destination\n",
    "basedir = '/media/roman/TeraTwo/website/GAv0/ca2/MESA/'\n",
    "\n",
    "# Population name\n",
    "population = 'ca2'\n",
    "\n",
    "# Population directory\n",
    "pop_dir = '/media/roman/TeraTwo/christian/{}'.format(population)\n",
    "\n",
    "# Input and output directories (output with respect to basedir)\n",
    "models = {\n",
    "    '{}/MESA/photosphere/'.format(pop_dir): 'models/photosphere/',\n",
    "    '{}/MESA/tau_100/'.format(pop_dir): 'models/tau_100/',\n",
    "}\n",
    "\n",
    "for model_dir in models:\n",
    "    for model in glob.glob(model_dir + '/*'):\n",
    "        if not os.path.isfile(model + '/inlist_project'):\n",
    "            continue\n",
    "        export_MESA_model(model, basedir + '/' + models[model_dir])\n",
    "\n",
    "# Export the BC tables\n",
    "shutil.copytree('{}/TABLES/MESA_BC/'.format(pop_dir), destination := (basedir + '/tables'))\n",
    "os.remove(destination + '/diagnostic.pkl')\n",
    "\n",
    "# Export the MESA patch\n",
    "shutil.copy('/home/roman/MESA/custom.patch', basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da1612",
   "metadata": {},
   "source": [
    "## Test FITS files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fc999",
   "metadata": {},
   "source": [
    "Load headers from all FITS files in a directory for simultaneous inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8f0d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258797/3954192025.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for model in tqdm.tqdm_notebook(models):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f292d01514e4c11a7692b05e46509e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = glob.glob('/media/roman/TeraTwo/website/GAv0/ca1/PHOENIX/*')\n",
    "\n",
    "result = {}\n",
    "eheu = {}\n",
    "abs_eheu = {}\n",
    "\n",
    "for model in tqdm.tqdm_notebook(models):\n",
    "    h = fits.open(model)\n",
    "\n",
    "    # Get main headers\n",
    "    header = h[0].header\n",
    "    for key in header:\n",
    "        if key in result:\n",
    "            result[key] += [header[key]]\n",
    "        else:\n",
    "            result[key] = [header[key]]\n",
    "\n",
    "    # Locate abundances hdul\n",
    "    index = 0\n",
    "    for i in range(1, len(h)):\n",
    "        if ('TABLE' in h[i].header) and (h[i].header['TABLE'] == 'Chemical composition'):\n",
    "            index = i\n",
    "    if index < 0:\n",
    "        raise ValueError('Cannot find abundances')\n",
    "\n",
    "    # Load abundances\n",
    "    for element in h[index].data:\n",
    "        if len(element) > 1:\n",
    "            if element[0] in eheu:\n",
    "                eheu[element[0]] += [element[1]]\n",
    "            else:\n",
    "                eheu[element[0]] = [element[1]]\n",
    "        if len(element) > 2:\n",
    "            if element[0] in abs_eheu:\n",
    "                abs_eheu[element[0]] += [element[2]]\n",
    "            else:\n",
    "                abs_eheu[element[0]] = [element[2]]\n",
    "    h.close()\n",
    "\n",
    "# Uniquify all output\n",
    "for key in result:\n",
    "    result[key] = np.unique(result[key])\n",
    "\n",
    "for key in eheu:\n",
    "    eheu[key] = np.unique(eheu[key])\n",
    "\n",
    "for key in abs_eheu:\n",
    "    abs_eheu[key] = np.unique(abs_eheu[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
